{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we train sub-linear complexity stochastic GMM algorithms for various datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import shutil\n",
    "from utils import create_histograms, create_soft_features, read_parameters\n",
    "import pickle\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean \n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "name                    = 'pokerdvs'\n",
    "\n",
    "# data parameters\n",
    "training_path           = '../data-generation/exp/'+name+'_train_sp10' # path to the training npy file\n",
    "test_path               = '../data-generation/exp/'+name+'_test_sp10' # path to the test npy file\n",
    "sample_percentage       = 100 # take a data sample for the training set instead of full data (between 1 and 100)\n",
    "\n",
    "# model parameters\n",
    "algorithm               = 1 # 0:k-means | 1:u-S-GMM | 2:S-GMM\n",
    "M                       = 500 # number of cluster centers\n",
    "H                       = 5 # number of clusters considered for each data point\n",
    "R                       = 40 # number of new samples\n",
    "Nprime                  = 2**15 # size of subset | set to 0 to disable coreset creation\n",
    "stream                  = False # stream data from harddrive to build coreset | training data not loaded and only works when using coresets\n",
    "chain_length            = 10 # chain length for AFK-MCÂ² seeding\n",
    "convergence_threshold   = 0.0001  # < 1 for convergence threshold | >= 1 for epochs\n",
    "\n",
    "# output parameters\n",
    "trials                  = 5 # if > 1 uses intel TBB for parallelisation\n",
    "top_k                   = 1 # save the k best clusters during inference\n",
    "inference               = True # save cluster assignments for training and test datasets (when streaming doesn't work for training set)\n",
    "save_additional_info    = 0 # 1: save centers, error, and priors across iterations | 2: only priors\n",
    "verbose                 = 0 # display more output (1 or 2 for even more information)\n",
    "\n",
    "# notebook parameters\n",
    "clustering_analysis     = False # runs clustering analysis on the results\n",
    "classification          = True # runs classification on the results\n",
    "save_figures            = False # save figures after plotting\n",
    "\n",
    "# classification parameters\n",
    "torch_mlp               = False # do an MLP classifier instead of logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run C++ GMM standalone executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "    \n",
    "algo_type = str(algorithm)\n",
    "\n",
    "# defining save path\n",
    "save_path = Path('milled_nbs/{0}/Hp-{1}_R-{2}_M-{3}_mc-{4}_th-{5}/{6}/{7}'.format(name, H, R, M, chain_length, convergence_threshold, algo_type, Nprime))\n",
    "    \n",
    "# make folder and if exists empty it  \n",
    "if save_path.exists():\n",
    "    shutil.rmtree(save_path)\n",
    "    \n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if algorithm == 0:\n",
    "    # k-means baselines\n",
    "    cmd_list = ['../build/release/km', \n",
    "                training_path, \n",
    "                test_path, \n",
    "                str(save_path), \n",
    "                str(sample_percentage),\n",
    "                str(M), \n",
    "                str(Nprime),\n",
    "                str(int(stream)), \n",
    "                str(convergence_threshold), \n",
    "                str(trials), \n",
    "                str(int(inference)),\n",
    "                str(int(save_additional_info)), \n",
    "                str(int(verbose)), \n",
    "               ]\n",
    "else:\n",
    "    # gmm algorithms\n",
    "    cmd_list = ['../build/release/gmm',\n",
    "                training_path, \n",
    "                test_path, \n",
    "                str(save_path),\n",
    "                str(sample_percentage),\n",
    "                str(algorithm),\n",
    "                str(M),   \n",
    "                str(H),                                   \n",
    "                str(R),                                    \n",
    "                str(Nprime),\n",
    "                str(int(stream)),                        \n",
    "                str(chain_length),                                     \n",
    "                str(convergence_threshold), \n",
    "                str(trials),\n",
    "                str(top_k),\n",
    "                str(int(inference)),\n",
    "                str(0),\n",
    "                str(int(save_additional_info)), \n",
    "                str(int(verbose)),\n",
    "               ]\n",
    "\n",
    "# running C++ executable within Python\n",
    "p = subprocess.run(cmd_list, capture_output=True, universal_newlines=True)\n",
    "if len(p.stdout) > 0: print(p.stdout)\n",
    "if len(p.stderr) > 0: print(p.stderr)\n",
    "\n",
    "print('--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# name of algorithms\n",
    "algorithms = {'0':'k-means',\n",
    "              '1':'u-S-GMM',\n",
    "              '2':'S-GMM'}\n",
    "\n",
    "# make analysis folder where we dump our results\n",
    "analysis_path = save_path/'analysis'\n",
    "analysis_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# condition to check if a test dataset is provided\n",
    "test = False if len(test_path) == 0 else True\n",
    "\n",
    "# directory where files are saved\n",
    "save_dir = [save_path] if trials == 1 else [folder for folder in save_path.iterdir() if not folder.name.startswith('.') and folder != analysis_path]\n",
    "\n",
    "if clustering_analysis:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print('clustering analysis for algorithm: %s' % algorithms[algo_type], 'over %s run(s)' % len(save_dir))\n",
    "    \n",
    "    analysis = {}\n",
    "    for i, s in enumerate(save_dir):\n",
    "        print(s)\n",
    "        folder = s.parts[-2] if trials == 1 else s.parts[-3]\n",
    "\n",
    "        # read the parameters of the model\n",
    "        model_parameters = read_parameters(s)\n",
    "        \n",
    "        # initialise the key for the algorithm being used if not already done\n",
    "        if folder not in analysis.keys():\n",
    "            if folder == '0':\n",
    "                analysis[folder] = {'M':M,\n",
    "                                    'lwcs':Nprime, \n",
    "                                    'thres':convergence_threshold,\n",
    "                                    'trials':trials,\n",
    "                                    'error':np.zeros(trials), \n",
    "                                    'dist_eval':np.zeros(trials), \n",
    "                                    't_em':np.zeros(trials),\n",
    "                                    't_seed':np.zeros(trials),\n",
    "                                    'iter':np.zeros(trials)\n",
    "                                   }\n",
    "            else:\n",
    "                analysis[folder] = {'M':M,\n",
    "                                    'H':H,\n",
    "                                    'R':R, \n",
    "                                    'lwcs':Nprime, \n",
    "                                    'chain':chain_length,\n",
    "                                    'thres':convergence_threshold,\n",
    "                                    'trials':trials,\n",
    "                                    'error':np.zeros(trials), \n",
    "                                    'dist_eval':np.zeros(trials), \n",
    "                                    't_em':np.zeros(trials),\n",
    "                                    't_seed':np.zeros(trials),\n",
    "                                    'iter':np.zeros(trials)\n",
    "                                   }\n",
    "\n",
    "        # quantization error\n",
    "        if test:\n",
    "            error = np.load(s/'te_quantization.npy')\n",
    "        else:\n",
    "            error = np.load(s/'tr_quantization'/str(str(model_parameters.iteration[-1])+'.npy'))\n",
    "        analysis[folder]['error'][i] = error[0]\n",
    "        print('error:', error[0])\n",
    "        \n",
    "        # distance evaluations\n",
    "        distances = np.load(s/'distance_evals.npy')\n",
    "        analysis[folder]['dist_eval'][i] = distances[0]*distances[1]\n",
    "        print('distance evaluations:', distances[0]*distances[1])\n",
    "        \n",
    "        # coreset and seeding runtime\n",
    "        runtime = np.load(s/'runtime.npy')\n",
    "        analysis[folder]['t_seed'][i] = runtime[0]\n",
    "        print('seeding runtime', runtime[0])\n",
    "        \n",
    "        # EM runtime\n",
    "        analysis[folder]['t_em'][i] = runtime[1]\n",
    "        print('EM runtime:', runtime[1])\n",
    "        \n",
    "        # number of iterations\n",
    "        analysis[folder]['iter'][i] = model_parameters.iteration[-1]\n",
    "        print('iterations:', model_parameters.iteration[-1])\n",
    "        \n",
    "        # Quantization error across iterations\n",
    "        if save_additional_info > 0:\n",
    "            error = [np.load(s/'tr_quantization'/str(str(i)+'.npy'))[0] for i in model_parameters.iteration]\n",
    "            \n",
    "            error_fig = plt.figure()\n",
    "            plt.plot(model_parameters.iteration[1:], error[1:])\n",
    "            plt.title('Quantization error across iterations')\n",
    "            plt.show()\n",
    "            \n",
    "            if save_figures:\n",
    "                error_fig.savefig(save_path/'analysis'/str(str(i)+'_'+'quantization_iters.pdf'), bbox_inches='tight')\n",
    "                \n",
    "        # Free energy across iterations\n",
    "        free_energy_fig = plt.figure()\n",
    "        plt.plot(model_parameters.iteration[1:], model_parameters.free_energy[1:])\n",
    "        plt.title('Free energy across iterations')\n",
    "        plt.show()\n",
    "        \n",
    "        if save_figures:\n",
    "            free_energy_fig.savefig(save_path/'analysis'/str(str(i)+'_'+'free_energy_iters.pdf'), bbox_inches='tight')\n",
    "            \n",
    "        # Sigma across iterations\n",
    "        sigma_fig = plt.figure()\n",
    "        plt.plot(model_parameters.iteration[1:], model_parameters.sigma[1:])\n",
    "        plt.title('Sigma across iterations')\n",
    "        plt.show()\n",
    "        \n",
    "        if save_figures:\n",
    "            sigma_fig.savefig(save_path/'analysis'/str(str(i)+'_'+'sigma_iters.pdf'), bbox_inches='tight')\n",
    "        \n",
    "        # Prior decay\n",
    "        prior_path = s/'priors'\n",
    "        if prior_path.exists() and save_additional_info > 0:\n",
    "            # loading priors\n",
    "            priors = np.array([np.load(prior_path/str(str(i)+'.npy')) for i in model_parameters.iteration]).T\n",
    "\n",
    "            # offset according to uniform prior values (we want to see how it moves from the uniform)\n",
    "            offset = mcolors.TwoSlopeNorm(vcenter=priors[0,0])\n",
    "\n",
    "            # plotting and formatting\n",
    "            fig = plt.figure()\n",
    "            ax = sns.heatmap(offset(priors),cmap=sns.diverging_palette(220, 20, n=128))\n",
    "            ax.set_title('Priors Decay (M=%s)' % M)\n",
    "            ax.set_ylabel('Priors')\n",
    "            ax.set_xlabel('Iterations')\n",
    "            \n",
    "            if save_figures:\n",
    "                fig.savefig(save_path/str('priors_%s.pdf' %M))\n",
    "                \n",
    "    # average statistics\n",
    "    if trials > 1:\n",
    "        # average iterations\n",
    "        print('average iterations:', np.mean(analysis[algo_type]['iter']), '\\u00b1', np.std(analysis[algo_type]['iter']))\n",
    "        \n",
    "        #average runtime\n",
    "        print('average runtime:',\\\n",
    "              np.mean(analysis[algo_type]['t_seed'] + analysis[algo_type]['t_em']),\\\n",
    "              '\\u00b1',\\\n",
    "              np.std(analysis[algo_type]['t_seed'] + analysis[algo_type]['t_em']))\n",
    "        \n",
    "        # average operations\n",
    "        print('average operations:', np.mean(analysis[algo_type]['dist_eval']), '\\u00b1', np.std(analysis[algo_type]['dist_eval']))\n",
    "        \n",
    "        #average error\n",
    "        print('average error:', np.mean(analysis[algo_type]['error']), '\\u00b1', np.std(analysis[algo_type]['error']))\n",
    "\n",
    "    # save analysis dictionary    \n",
    "    filename = save_path/'analysis'/'analysis.pickle'\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(analysis, f)\n",
    "            \n",
    "    print('--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if classification and test:\n",
    "    from logreg import LogisticRegression\n",
    "    from mlp import MLP\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "    from torch.optim.lr_scheduler import StepLR\n",
    "    from sklearn import preprocessing\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    print('classification for algorithm: %s' % algorithms[algo_type], 'over %s run(s)' % len(save_dir))\n",
    "    \n",
    "    scores = np.zeros(len(save_dir))\n",
    "    for i, s in enumerate(save_dir):\n",
    "        \n",
    "        # creating histograms from hard clusters\n",
    "        train_features, train_labels = create_histograms(s, training_path, M, train=True)\n",
    "        test_features, test_labels = create_histograms(s, training_path, M, train=False)\n",
    "        \n",
    "        # scale features to 0 mean and 1 variance\n",
    "        scaler = preprocessing.StandardScaler().fit(train_features)\n",
    "        train_features = scaler.transform(train_features)\n",
    "        test_features = scaler.transform(test_features)\n",
    "            \n",
    "        # creating dataloaders\n",
    "        training_dataset = TensorDataset(torch.Tensor(train_features),torch.Tensor(train_labels))\n",
    "        training_dataloader = DataLoader(training_dataset, batch_size=128)\n",
    "        \n",
    "        test_dataset = TensorDataset(torch.Tensor(test_features),torch.Tensor(test_labels))\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=128)\n",
    "        \n",
    "        # finding unique classes\n",
    "        classes = np.unique(test_labels)\n",
    "        \n",
    "        # training classifier\n",
    "        if torch_mlp:\n",
    "            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "            mlp = MLP(train_features.shape[1], 128, len(classes)) # single layer MLP\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.SGD(mlp.parameters(), lr=0.1, momentum=0, weight_decay=0)\n",
    "            scheduler = StepLR(optimizer, step_size=50, gamma=1)\n",
    "            \n",
    "            # train model\n",
    "            mlp.train()\n",
    "            for epoch in range(200):  # loop over the dataset multiple times\n",
    "                for inputs, targets in training_dataloader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    \n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward + backward + optimize\n",
    "                    outputs = mlp(inputs)\n",
    "                    loss = criterion(outputs, targets.long())\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            # Decay Learning Rate\n",
    "            scheduler.step()\n",
    "            \n",
    "            # test model\n",
    "            mlp.eval()\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            with torch.no_grad():\n",
    "                for t_inputs, t_targets in test_dataloader:\n",
    "                    t_inputs, t_targets = t_inputs.to(device), t_targets.to(device)\n",
    "                    t_outputs = mlp(t_inputs)\n",
    "                    t_loss = criterion(t_outputs, t_targets.long())\n",
    "                    _, predicted = torch.max(t_outputs, 1)\n",
    "                    total += t_targets.size(0)\n",
    "                    correct += (predicted == t_targets).sum().item()\n",
    "            scores[i] = correct / total\n",
    "        else:\n",
    "            logreg = LogisticRegression(train_features.shape[1], len(classes), epochs=200, lr=0.01, step_size=30, gamma=1, momentum=0, weight_decay=0)\n",
    "            logreg.fit(training_dataloader)\n",
    "            scores[i] = logreg.score(test_dataloader)\n",
    "        \n",
    "    # print mean score\n",
    "    classifier_name = \"MLP\" if torch_mlp else \"Logistic regression\"\n",
    "    print(classifier_name, 'classifier: %s%% \\u00B1 %s' % (np.mean(scores[:]*100),np.std(scores[:]*100)))\n",
    "    \n",
    "    # save results\n",
    "    filename = save_path/'analysis'/'classification.npy'\n",
    "    np.save(filename, scores)\n",
    "        \n",
    "    print('--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.22.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
